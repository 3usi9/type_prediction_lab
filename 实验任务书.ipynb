{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4a67b31",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 实验说明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb974cf-50fc-426d-bb98-a14fca681695",
   "metadata": {
    "tags": []
   },
   "source": [
    "本实验基于`naturalcc`工具集，它是业界首个专注代码智能的深度模型开源训练工具集，包含了对业界现有的代码模型和下游任务的性能评价。相关论文发表在软件工程顶级会议ICSE上，参考文献 [NaturalCC: An Open-Source Toolkit for Code Intelligence](https://xcodemind.github.io/papers/icse22_naturalcc_camera_submitted.pdf)，实验要求使用`naturalcc`工具集复现类型推导任务中的经典方法`Typilus`，此方法发表在2020年的程序语言顶级会议PLDI上，相关文献为[Typilus: neural type hints](https://arxiv.org/pdf/2004.10657.pdf)。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6affe41c-3c07-48c9-a5fd-5b06703a759d",
   "metadata": {},
   "source": [
    "实验分为五个部分，环境准备、数据获取、模型和超参数配置、模型训练与评价、拓展研究。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f29ae74-04c9-48c8-bcb7-b198a2fedfd2",
   "metadata": {},
   "source": [
    "完整复现Typilus需要计算节点的内存大于或等于`128GB`，显存大于或等于 `32GB`，如无计算节点，建议裁剪数据集，以及使用 [Google Colab](http://colab.research.google.com) (可以提供12GB的内存和一张16GB显存的 Tesla T4显卡）\n",
    "\n",
    "(colab不支持docker，所以不建议使用）\n",
    "\n",
    "实验只能在Linux系统上运行，可以选择安装双系统、VMWare虚拟机或WSL子系统（Windows Subsystem for Linux）进行实验。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dfc1bf-9deb-4199-816f-0e8985edd945",
   "metadata": {},
   "source": [
    "为避免包冲突，建议使用[Anaconda](http://anaconda.org)管理Python环境。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35468579-5ed3-4701-bf50-26596407d030",
   "metadata": {
    "tags": []
   },
   "source": [
    "## NaturalCC 环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c5586-80e9-4e42-a5fa-28d7ec263be4",
   "metadata": {
    "tags": []
   },
   "source": [
    "首先在GitHub上下载`naturalcc`工具集，执行下面的命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e7130ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'naturalcc'...\n",
      "remote: Enumerating objects: 2740, done.\u001b[K\n",
      "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
      "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
      "remote: Total 2740 (delta 36), reused 33 (delta 9), pack-reused 2638\u001b[K\n",
      "Receiving objects: 100% (2740/2740), 82.38 MiB | 7.65 MiB/s, done.\n",
      "Resolving deltas: 100% (1135/1135), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/CGCL-codes/naturalcc.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc7bc33",
   "metadata": {
    "tags": []
   },
   "source": [
    "之后在本地安装naturalcc环境，需要提前安装pytorch，此命令只需要执行一次。\n",
    "推荐使用 Anaconda 虚拟环境容器，避免影响本地Python环境。Anaconda可以在[这里](https://www.anaconda.com/)获取。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ea386e-1537-4f06-b848-ec7e675da8d6",
   "metadata": {},
   "source": [
    "Python要求最低版本3.8，安装完成后，执行下面的命令"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87d98f10",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dell/Code/jupyter/naturalcc\n"
     ]
    }
   ],
   "source": [
    "%cd naturalcc\n",
    "!pip install -r requirements.txt\n",
    "!pip install --editable .\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da96ef62-d89d-4aa2-8af5-e8320f4ac014",
   "metadata": {
    "tags": []
   },
   "source": [
    "### [GPU训练] 需要注意的地方"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f69d47",
   "metadata": {},
   "source": [
    "训练过程依赖[pytorch库](https://pytorch.org)和[dgl库](https://www.dgl.ai)，如果使用GPU+CUDA训练，需要确保所安装的库版本与本机的CUDA版本对应，例如CUDA 11.0+需要安装```torch+cu110, dgl-cu110```，如果仅使用CPU训练，则只需要安装CPU版本的`torch`和`dgl`即可\n",
    "\n",
    "注意：conda安装pytorch可能只会安装cpu版本（无论是否选择gpu包），因此建议使用pip安装。如果你有gpu，则推荐的安装方法：\n",
    "\n",
    "~~~shell\n",
    "pip3 install torch==1.12+cu113 --no-cache-dir --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "conda install -c dglteam dgl-cuda11.3\n",
    "~~~\n",
    "\n",
    "其中`torch==1.12`为pytorch的版本（我用的是1.12，注意不要用最新版1.13），`cu113`和`dgl-cuda11.3`对应于你自己本机的CUDA版本（可以使用命令`nvcc -V`查看，我用的是CUDA==11.3，要注意pytorch较新的版本不再支持CUDA 10及以下），注意`--extra-index-url`里面也有一个cu113要改"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f8a1ee-c596-4cd8-bc58-3206d5db3df6",
   "metadata": {},
   "source": [
    "在使用GPU训练前需要通过`gpustat`或`nvidia-smi`检查GPU是否已经正确安装，如下所示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1aa6bdf-f45c-45f6-820e-7c2f4cf2749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdell-gpu           \u001b[m  Wed Oct 12 11:02:22 2022  \u001b[1m\u001b[30m460.56\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 29'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 31'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m24268\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1d04f8-8ac4-49aa-8b3a-9e66c5fbbf5e",
   "metadata": {},
   "source": [
    "## Typilus环境"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddba779-089c-45b2-88b8-1d4f0b1c4249",
   "metadata": {},
   "source": [
    "构建Typilus数据集需要使用`docker`，在电脑上安装`docker`后，获取`typilus`的源代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a140db-9e7f-4496-870f-6e8144984892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'typilus'...\n",
      "remote: Enumerating objects: 159, done.\u001b[K\n",
      "remote: Counting objects: 100% (159/159), done.\u001b[K\n",
      "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
      "remote: Total 159 (delta 38), reused 111 (delta 15), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (159/159), 162.86 KiB | 2.06 MiB/s, done.\n",
      "Resolving deltas: 100% (38/38), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/typilus/typilus.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca3d190-79d8-4919-907a-ca6410e88fde",
   "metadata": {},
   "source": [
    "之后在 `typilus/src/data_preparation`目录构建docker镜像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%cd typilus/src/data_preparation/\n",
    "!docker build -t typilus-env ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 注：在linux系统运行docker需要root用户权限。如果是在实验室的服务器上运行，则需要事先向管理员索要root权限，或通过管理员加入docker用户组。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据获取"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bfba80-f997-4aa2-92cd-6000fbc9df1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Typilus Graph 构建"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72747e2f-a6be-4e37-bc12-2d47cf2dcd40",
   "metadata": {},
   "source": [
    "在开始训练之前，我们首先需要获得训练所需的数据，我们将首先使用`Typilus`内置的数据处理程序将Python数据转换为Typilus Graph，然后把graph导入`naturalcc`进行训练和预测"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2cec65-6009-4cbe-9bc5-cf4f50400868",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "运行刚才构建的docker镜像，并设置Typilus训练数据保存的位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2ffcae-3477-4317-bf67-5958a8af2c69",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "!docker run --rm -it -v xxx/yyy/zzz:/usr/data typilus-env:latest bash"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> `docker run` 是启动 docker 容器的命令。参数`-it`表示使用交互模式，新建一个终端。`-v xxx/yyy/zzz:/usr/data`表示挂载主机目录到容器的目录，当你指定一个主机目录为`xxx/yyy/zzz`的时候，就可以在主机上的这个文件夹里面看到docker容器中`/usr/data`路径下的文件了。所以这里的`xxx/yyy/zzz`要替换成你自己的机器上一个空间比较大的位置。\n",
    "注意：一旦关闭容器所有的数据就会丢失，这些流程就要重新来过，所以不要关闭容器！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1251b23a",
   "metadata": {},
   "source": [
    "参数`--rm`表示stop container后会自动删掉这个container, 在windows环境中需要给\n",
    "-v xxx/yyy/zzz:/usr/data添加双引号\"\", xxx/yyy/zzz为windows上想要指定得主机目录。typilus-env:latest的:后的是想创建的image的标签"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866e88d-c8e1-4c85-a82a-13ededfd7f4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "在Docker shell中，输入下面的命令来构建数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f46235-50ce-41a7-bd59-9dfbd706f4a5",
   "metadata": {},
   "source": [
    "``bash scripts/prepare_data.sh metadata/typedRepos.txt``"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9d578b-6df3-4875-8aca-e9a2f4316c83",
   "metadata": {},
   "source": [
    "*注意：这条命令可能会执行若干天，因为需要从github clone500余个代码存储库（这需要大量的存储空间）。关于命令执行时间过长和死循环的问题，可以参考[这里](https://github.com/typilus/typilus/issues/1)*\n",
    "\n",
    "以下是我的暴力解决方案，仅供参考：\n",
    "\n",
    "如果卡顿很久不再继续，可以手动 Ctrl+c 杀死当前的进程。如果后面又会卡掉，多这样做几次再停掉。会有一部分数据集构建成功。\n",
    "\n",
    "实际上，你可以在`typilus/src/data_preparation/scripts/`下发现卡住的脚本`prepare_data.sh`，它会卡在第35行开始的循环内：\n",
    "\n",
    "~~~shell\n",
    "# Create dataset spec\n",
    "for repo in ./*; do\n",
    "    cd ./$repo\n",
    "    echo $(git remote get-url origin) $(git rev-parse HEAD) >> ../../dataset.spec\n",
    "    cd ..\n",
    "done\n",
    "~~~\n",
    "\n",
    "如果你手动停掉了这个循环，那么你需要把脚本`prepare_data.sh`在该循环后面的命令手动执行一遍。注意，第41行`cd ..`之后所在的目录是`/usr/data`（不是你自己机子的目录，是docker容器内的目录）。\n",
    "\n",
    "这两个循环之后的过程是不会卡住的（用pytype进行类型分析的过程需要较长时间，但最终会执行完毕，只要你肯等）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d50136-5b09-4aa5-a11c-952df046d8dd",
   "metadata": {},
   "source": [
    "获取的数据保存在 `xxx/yyy/zzz/graph-dataset-split` （本机地址）`/usr/data/graph-dataset-split`（docker容器地址）中，使用Tree命令观察\n",
    "\n",
    "（若在docker容器中执行这一步，则要先在docker容器中安装tree：`sudo apt-get install tree`）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "479be175-f41e-4b09-8c36-403cd3d9a01b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/mnt/gold/bizq/Typilus_data/graph-dataset-split\u001b[00m\n",
      "├── \u001b[01;34mtest\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-000.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-001.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-002.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-003.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-004.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-005.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-006.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-007.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-008.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-009.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-010.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-011.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-012.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-013.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-014.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-015.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-016.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-017.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-018.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-019.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-020.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-021.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-022.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-023.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-024.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-025.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-026.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-027.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-028.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-029.jsonl.gz\u001b[00m\n",
      "│   └── \u001b[01;31mgraph-030.jsonl.gz\u001b[00m\n",
      "├── \u001b[01;34mtrain\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-000.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-001.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-002.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-003.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-004.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-005.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-006.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-007.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-008.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-009.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-010.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-011.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-012.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-013.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-014.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-015.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-016.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-017.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-018.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-019.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-020.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-021.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-022.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-023.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-024.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-025.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-026.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-027.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-028.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-029.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-030.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-031.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-032.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-033.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-034.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-035.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-036.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-037.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-038.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-039.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-040.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-041.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-042.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-043.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-044.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-045.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-046.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-047.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-048.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-049.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-050.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-051.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-052.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-053.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-054.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-055.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-056.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-057.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-058.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-059.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-060.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-061.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-062.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-063.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-064.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-065.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-066.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-067.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-068.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-069.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-070.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-071.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-072.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-073.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-074.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-075.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-076.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-077.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-078.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-079.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-080.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-081.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-082.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-083.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-084.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-085.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-086.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-087.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-088.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-089.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-090.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-091.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-092.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-093.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-094.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-095.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-096.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-097.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-098.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-099.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-100.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-101.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-102.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-103.jsonl.gz\u001b[00m\n",
      "│   ├── \u001b[01;31mgraph-104.jsonl.gz\u001b[00m\n",
      "│   └── \u001b[01;31mgraph-105.jsonl.gz\u001b[00m\n",
      "└── \u001b[01;34mvalid\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-000.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-001.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-002.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-003.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-004.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-005.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-006.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-007.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-008.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-009.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-010.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-011.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-012.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-013.jsonl.gz\u001b[00m\n",
      "    ├── \u001b[01;31mgraph-014.jsonl.gz\u001b[00m\n",
      "    └── \u001b[01;31mgraph-015.jsonl.gz\u001b[00m\n",
      "\n",
      "3 directories, 153 files\n"
     ]
    }
   ],
   "source": [
    "!tree /mnt/gold/bizq/Typilus_data/graph-dataset-split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdb76de-5628-41d0-b63e-1cc332c38e07",
   "metadata": {},
   "source": [
    "## NaturalCC 数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40801fd0-2ea3-4fe3-86ec-4612b72c315f",
   "metadata": {},
   "source": [
    "接下来把生成的Typilus Graph导入NaturalCC\n",
    "\n",
    "如果上述过程执行成功，这一步开始就不用docker了，可以另开一个终端执行（先不要急着关闭docker容器！关闭容器后如果再想对数据集操作就需要从头开始！）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "数据的处理过程包含了两个阶段，首先将原始数据整理为naturalcc统一的格式，接下来对数据进行binarize，以适合模型训练。\n",
    "\n",
    ">首先，找到typilus配置文件`naturalcc/ncc_dataset/typilus/preprocess/typilus.yml`，修改以下几项为：\n",
    "> ~~~yaml\n",
    ">  trainpref: ~/typilus/attributes/train #\", metavar=\"FP\", default=None, help=\"train file prefix\"\n",
    ">  validpref: ~/typilus/attributes/valid #\", metavar=\"FP\", default=None, help=\"comma separated, valid file prefixes\"\n",
    ">  testpref:  ~/typilus/attributes/test  #\", metavar=\"FP\", default=None, help=\"comma separated, test file prefixes\"\n",
    ">~~~\n",
    ">以及（去掉并行运行）\n",
    ">~~~yaml\n",
    ">  workers: 1 # \", metavar=\"N\", default=1, type=int, help=\"number of parallel workers\"\n",
    ">~~~\n",
    "\n",
    "以上两步已经在新的代码中被修复了，不用管。\n",
    "\n",
    "然后运行（会有点慢）："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "> 以下三行代码可以放入一个.py文件，然后使用`python xxx.py`执行。函数`prepare_dataset()`中的参数`typilus_path`改成你自己构建数据集所在的目录，也就是`./graph-dataset-split/`的上级目录\n",
    "> 注意：这个文件应放在之前git clone得到的`naturalcc`文件夹下，并以该文件夹为工作目录执行！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dffdc73c-0180-4519-a030-01e7a2538657",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2022-10-16 08:59:19]    INFO >> The typilus graph is migrated to NaturalCC directory. \n",
      "To re-migrate, please delete the directory '/mnt/gold/bizq/ncc_data/typilus/raw' (dataset_migration.py:24, dataset_migration())\u001b[0m\n",
      "\u001b[32m[2022-10-16 08:59:19]    INFO >> The typilus dataset is already flattened, to re-flatten the dataset, please delete the directory '/mnt/gold/bizq/ncc_data/typilus/attributes'. (flatten.py:43, flatten())\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import ncc_dataset\n",
    "ncc_dataset.prepare_dataset('typilus', typilus_path=\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b4482d2-0896-4040-9cb5-026366d6c027",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:30:49]    INFO >> Namespace(yaml_file='typilus') (preprocess.py:418, cli_main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:30:49]    INFO >> Load arguments in /home/dell/Code/jupyter/naturalcc/ncc_dataset/typilus/preprocess/typilus.yml (preprocess.py:420, cli_main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:30:49]    INFO >> {'preprocess': {'task': 'typilus', 'langs': ['nodes', 'edges', 'supernodes.annotation'], 'trainpref': '/mnt/gold/bizq/ncc_data/typilus/attributes/train', 'validpref': '/mnt/gold/bizq/ncc_data/typilus/attributes/valid', 'testpref': '/mnt/gold/bizq/ncc_data/typilus/attributes/test', 'dataset_impl': 'mmap', 'destdir': '/mnt/gold/bizq/ncc_data/typilus/type_inference/data-mmap', 'only_train': 1, 'edge_backward': 1, 'thresholds': [5, 5, 5], 'dicts': [None, None, None], 'nwords': [9999, 99, 99], 'padding_factor': 1, 'workers': 40}} (preprocess.py:422, cli_main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:30:49]    INFO >> mkdir /mnt/gold/bizq/ncc_data/typilus/type_inference/data-mmap for typilus task (preprocess.py:112, main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:30:49]    INFO >> Generating dictionaries with Train data files. (preprocess.py:143, main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:30:49]    INFO >> Filenames = ['/mnt/gold/bizq/ncc_data/typilus/attributes/train.nodes']. (preprocess.py:175, main())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:31:56]    INFO >> The dictionary for lang=nodes will be saved in /mnt/gold/bizq/ncc_data/typilus/type_inference/data-mmap/nodes.dict.json (preprocess.py:186, main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:31:56]    INFO >> Filenames = ['/mnt/gold/bizq/ncc_data/typilus/attributes/train.edges']. (preprocess.py:175, main())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:32:43]    INFO >> The dictionary for lang=edges will be saved in /mnt/gold/bizq/ncc_data/typilus/type_inference/data-mmap/edges.dict.json (preprocess.py:186, main())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:32:43]    INFO >> Filenames = ['/mnt/gold/bizq/ncc_data/typilus/attributes/train.supernodes']. (preprocess.py:175, main())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:32:53]    INFO >> The dictionary for lang=supernodes.annotation will be saved in /mnt/gold/bizq/ncc_data/typilus/type_inference/data-mmap/supernodes.annotation.dict.json (preprocess.py:186, main())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:39:00]    INFO >> /mnt/gold/bizq/ncc_data/typilus/attributes/train.nodes: 105448 sents, 1344916190 tokens, 0.0% replaced by [UNK] (preprocess.py:250, make_binary_dataset())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:40:27]    INFO >> /mnt/gold/bizq/ncc_data/typilus/attributes/valid.nodes: 15005 sents, 199611770 tokens, 0.0% replaced by [UNK] (preprocess.py:250, make_binary_dataset())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 09:42:16]    INFO >> /mnt/gold/bizq/ncc_data/typilus/attributes/test.nodes: 30378 sents, 373456795 tokens, 0.0% replaced by [UNK] (preprocess.py:250, make_binary_dataset())\u001b[0m\n",
      " 11%|████                                | 11738/105448 [01:39<22:54, 68.18it/s]\u001b[32m[2022-10-16 09:44:02]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:44:02]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      " 11%|████                                | 11763/105448 [01:39<17:05, 91.39it/s]\u001b[32m[2022-10-16 09:44:02]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:44:02]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:44:02]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "\u001b[32m[2022-10-16 09:44:02]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      " 74%|██████████████████████████▋         | 78227/105448 [12:00<15:33, 29.15it/s]\u001b[32m[2022-10-16 09:54:23]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "100%|███████████████████████████████████| 105448/105448 [20:55<00:00, 83.97it/s]\n",
      " 11%|████▏                                 | 1644/15005 [00:13<04:49, 46.12it/s]\u001b[32m[2022-10-16 10:09:30]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "\u001b[32m[2022-10-16 10:09:30]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "100%|█████████████████████████████████████| 15005/15005 [03:00<00:00, 83.08it/s]\n",
      " 11%|████▏                                 | 3354/30378 [00:34<06:31, 69.11it/s]\u001b[32m[2022-10-16 10:13:42]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "\u001b[32m[2022-10-16 10:13:42]    INFO >> A graph is skipped (preprocess.py:382, make_dataset())\u001b[0m\n",
      "100%|█████████████████████████████████████| 30378/30378 [05:51<00:00, 86.38it/s]\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 10:20:54]    INFO >> /mnt/gold/bizq/ncc_data/typilus/attributes/train.supernodes: 105448 sents, 887006 tokens, 0.0% replaced by [UNK] (preprocess.py:349, make_supernodes_binary_dataset())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 10:21:14]    INFO >> /mnt/gold/bizq/ncc_data/typilus/attributes/valid.supernodes: 15005 sents, 108952 tokens, 0.0% replaced by [UNK] (preprocess.py:349, make_supernodes_binary_dataset())\u001b[0m\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "NaturalCC dataset and cache path: '/mnt/gold/bizq/ncc_data'\n",
      "Using backend: pytorch\n",
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-16 10:21:36]    INFO >> /mnt/gold/bizq/ncc_data/typilus/attributes/test.supernodes: 30378 sents, 243390 tokens, 0.0% replaced by [UNK] (preprocess.py:349, make_supernodes_binary_dataset())\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "ncc_dataset.binarize_dataset('typilus')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "以下是我踩过的坑：\n",
    "* FileNotFoundError: The dataset variable $NCC is not set, please first define the variable.\n",
    "解决方案：在linux终端运行命令`export NCC=xxx/yyy/zzz/data`，即设置环境变量NCC为你刚构建好的数据集的目录\n",
    "* ImportError: /usr/lib/x86_64-linux-gnu/libstdc++.so.6: version 'GLIBCXX_3.4.26' not found (required by <...>/envs/typilus/lib/python3.9/site-packages/scipy/linalg/_matfuncs_sqrtm_triu.cpython-39-x86_64-linux-gnu.so)\n",
    "解决方案：参考[这里](https://blog.csdn.net/weixin_36488777/article/details/116897183)，在环境变量LD_LIBRARY_PATH中用新的GCC库覆盖原来的GCC库。\n",
    "* RuntimeError: An attempt has been made to start a new process before the current process has finished its bootstrapping phase. This probably means that you are not using fork to start your child processes and you have forgotten to use the proper idiom in the main module: ...\n",
    "解决方案：多进程设置不能再使用了。把typilus配置文件`naturalcc/ncc_dataset/typilus/preprocess/typilus.yml`中最后一行的workers的40改成1（也就是上面的那一步）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5797c594-dbf1-48d3-bda4-b9fb1559d907",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c001bc-3cd8-4fdb-870c-aa0c526d1598",
   "metadata": {},
   "source": [
    "我们已经提供了训练代码，模型训练的过程只需要执行代码即可。这一步需要大量显存，建议裁剪数据集之后再进行训练。\n",
    "\n",
    "在训练前，需要在当前conda环境安装scikit-learn：`pip install scikit-learn`\n",
    "\n",
    "如果需要指定训练的GPU（默认0号卡），在`naturalcc/run/type_prediction/typilus/config/typilus.yml`中找到键`device_id`，并修改它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ac1a5fd-b95e-431b-b4a2-ea67b4da87c8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> Load arguments in naturalcc/run/type_prediction/typilus/config/typilus.yml (train.py:295, cli_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> {'criterion': 'typilus', 'optimizer': 'torch_adam', 'lr_scheduler': 'fixed', 'tokenizer': None, 'bpe': None, 'common': {'no_progress_bar': 0, 'log_interval': 50, 'log_format': 'simple', 'tensorboard_logdir': '', 'memory_efficient_fp16': 1, 'fp16_no_flatten_grads': 1, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'empty_cache_freq': 0, 'task': 'typilus', 'seed': 1, 'cpu': 0, 'fp16': 0, 'fp16_opt_level': '01', 'server_ip': '', 'server_port': '', 'bf16': 0}, 'dataset': {'num_workers': 0, 'skip_invalid_size_inputs_valid_test': 1, 'max_tokens': None, 'max_sentences': 32, 'required_batch_size_multiple': 8, 'dataset_impl': 'mmap', 'train_subset': 'train', 'valid_subset': 'valid', 'validate_interval': 1, 'fixed_validation_seed': None, 'disable_validation': 0, 'max_tokens_valid': None, 'max_sentences_valid': 512, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0}, 'distributed_training': {'distributed_world_size': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': 0, 'ddp_backend': 'c10d', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': None, 'find_unused_parameters': 0, 'fast_stat_sync': 0, 'broadcast_buffers': 0, 'global_sync_iter': 50, 'warmup_iterations': 500, 'local_rank': -1, 'block_momentum': 0.875, 'block_lr': 1, 'use_nbm': 0, 'average_sync': 0}, 'task': {'data': '/mnt/gold/bizq/ncc_data/typilus/type_inference/data-mmap', 'source_langs': ['nodes', 'edges'], 'target_langs': ['supernodes.annotation'], 'load_alignments': 0, 'left_pad_source': 0, 'left_pad_target': 0, 'max_source_positions': 512, 'max_target_positions': 30, 'upsample_primary': 1, 'truncate_source': 1, 'truncate_target': 1, 'append_eos_to_target': 1, 'eval_bleu': 1, 'eval_bleu_detok': 'space', 'eval_bleu_detok_args': None, 'eval_tokenized_bleu': 0, 'eval_bleu_remove_bpe': None, 'eval_bleu_args': None, 'eval_bleu_print_samples': 0}, 'model': {'arch': 'typilus', 'encoder_embed_dim': 64, 'max_subtoken_len': 5, 'encoder_hidden_size': 64, 'encoder_layers': 2, 'edge_types': 8, 'edge_in': 64, 'edge_out': 64, 'edge_backward': 1, 'timesteps': [7, 1], 'encoder_dropout': 0.1, 'decoder_dropout': 0.1}, 'optimization': {'max_epoch': 0, 'max_update': 0, 'clip_norm': 25, 'update_freq': [1], 'lrs': [0.0004], 'min_lr': -1, 'use_bmuf': 1, 'force_anneal': 0, 'warmup_updates': 0, 'lr_shrink': 0.98, 'margin': 2, 'sentence_avg': 1, 'adam': {'adam_betas': '(0.9, 0.999)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': 0}, 'weight_decay': 0.0, 'adam_epsilon': 1e-08, 'max_grad_norm': 1.0, 'num_train_epochs': 5, 'max_steps': -1, 'warmup_steps': 0, 'gradient_accumulation_steps': 1}, 'checkpoint': {'restore_file': 'checkpoint_last.pt', 'reset_dataloader': None, 'reset_lr_scheduler': None, 'reset_meters': None, 'reset_optimizer': None, 'optimizer_overrides': '{}', 'save_interval': 1, 'save_interval_updates': 0, 'keep_interval_updates': 0, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': 0, 'no_epoch_checkpoints': 1, 'no_last_checkpoints': 0, 'no_save_optimizer_state': None, 'best_checkpoint_metric': 'loss', 'maximize_best_checkpoint_metric': 1, 'patience': 10, 'save_dir': '/mnt/gold/bizq/ncc_data/.ncc/stack_overflow/summarization/csharp/data-mmap/seq2seq/checkpoints', 'should_continue': 0, 'model_name_or_path': None, 'cache_dir': None, 'logging_steps': 500, 'save_steps': 2000, 'save_total_limit': 2, 'overwrite_output_dir': 0, 'overwrite_cache': 0}, 'eval': {'path': '/mnt/gold/bizq/ncc_data/.ncc/stack_overflow/summarization/csharp/data-mmap/seq2seq/checkpoints/checkpoint_best.pt', 'result_path': None, 'remove_bpe': None, 'quiet': 0, 'model_overrides': '{}', 'max_sentences': 2048, 'beam': 1, 'nbest': 1, 'max_len_a': 0, 'max_len_b': 30, 'min_len': 1, 'match_source_len': 0, 'no_early_stop': 0, 'unnormalized': 0, 'no_beamable_mm': 0, 'lenpen': 1, 'unkpen': 0, 'replace_unk': None, 'sacrebleu': 0, 'score_reference': 0, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': 0, 'sampling_topk': -1, 'sampling_topp': -1, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': 0, 'print_step': 0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': 0, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': 0, 'retain_iter_history': 0, 'decoding_format': None, 'nltk_bleu': 1, 'rouge': 1}} (train.py:297, cli_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> single GPU training... (train.py:326, cli_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> [nodes] dictionary: 3873 types (typilus.py:102, setup_task())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> [edges] dictionary: 0 types (typilus.py:102, setup_task())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> [supernodes.annotation] dictionary: 65 types (typilus.py:106, setup_task())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> Typilus(\n",
      "  (encoder): GGNNEncoder(\n",
      "    (node_embedding): Embedding(3873, 64, padding_idx=0)\n",
      "    (node_layer): Sequential(\n",
      "      (0): Dropout(p=0.1, inplace=False)\n",
      "      (1): Linear(in_features=64, out_features=64, bias=False)\n",
      "      (2): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ggnns): ModuleList(\n",
      "      (0): GatedGNN(\n",
      "        (edge_weights): ModuleDict(\n",
      "          (CHILD): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (NEXT): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (NEXT_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_CHILD): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_NEXT): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_NEXT_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)\n",
      "        )\n",
      "        (rnn_cell): GRUCell(64, 64)\n",
      "      )\n",
      "      (1): GatedGNN(\n",
      "        (edge_weights): ModuleDict(\n",
      "          (CHILD): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (NEXT): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (NEXT_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_CHILD): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_NEXT): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_OCCURRENCE_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_SUBTOKEN_OF): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_LAST_LEXICAL_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_COMPUTED_FROM): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_NEXT_USE): Linear(in_features=64, out_features=64, bias=False)\n",
      "          (_RETURNS_TO): Linear(in_features=64, out_features=64, bias=False)\n",
      "        )\n",
      "        (rnn_cell): GRUCell(128, 64)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): DenseDecoder(\n",
      "    (cls_layers): Sequential(\n",
      "      (0): Linear(in_features=64, out_features=64, bias=False)\n",
      "      (1): Dropout(p=0.1, inplace=False)\n",
      "      (2): Linear(in_features=64, out_features=65, bias=True)\n",
      "    )\n",
      "  )\n",
      ") (train.py:215, single_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> model typilus, criterion TypilusCriterion (train.py:216, single_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:01]    INFO >> num. model params: 453569 (num. trained: 453569) (train.py:217, single_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> ***********************CUDA enviroments for all 1 workers*********************** (utils.py:530, pretty_print_cuda_env_list())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> rank   0: capabilities =  8.6  ; total memory = 24268 MB ; free memory = 22572 MB ; used memory = 1695 MB ; name = GeForce RTX 3090                         (utils.py:532, pretty_print_cuda_env_list())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> ***********************CUDA enviroments for all 1 workers*********************** (utils.py:540, pretty_print_cuda_env_list())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> training on 1 GPUs (train.py:224, single_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> max tokens per GPU = None and max sentences per GPU = 32 (train.py:225, single_main())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> no existing checkpoint found /mnt/gold/bizq/ncc_data/.ncc/stack_overflow/summarization/csharp/data-mmap/seq2seq/checkpoints/checkpoint_last.pt (ncc_trainers.py:299, load_checkpoint())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:05]    INFO >> loading train data for epoch 1 (ncc_trainers.py:314, get_train_iterator())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:06]    INFO >> NOTE: your device may support faster training with fp16 or --amp (ncc_trainers.py:183, _setup_optimizer())\u001b[0m\n",
      "/home/dell/Code/jupyter/naturalcc/ncc/utils/gradient_clip/fairseq_clip.py:56: UserWarning: amp_C fused kernels unavailable, disabling multi_tensor_l2norm; you may get better performance by installing NVIDIA's apex library\n",
      "  warnings.warn(\n",
      "\u001b[32m[2022-10-17 15:35:08]    INFO >> epoch 001 | loss 5.446 | wps 2410 | ups 5.05 | wpb 468.7 | bsz 468.7 | num_updates 10 | lr 0.0004 | gnorm 2.981 | clip 0 | train_wall 2 | gb_free 18.2 | wall 3 (progress_bar.py:267, print())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:08]    INFO >> epoch 001 | valid on 'valid' subset | loss 6.07 | wps 0 | wpb 607 | bsz 607 | num_updates 10 (progress_bar.py:267, print())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:08]    INFO >> saved checkpoint /mnt/gold/bizq/ncc_data/.ncc/stack_overflow/summarization/csharp/data-mmap/seq2seq/checkpoints/checkpoint_best.pt (epoch 1 @ 10 updates, score 6.07) (writing took 0.203210 seconds) (checkpoint_utils.py:78, save_checkpoint())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:10]    INFO >> epoch 002 | loss 5.495 | wps 1953.8 | ups 4.17 | wpb 468.7 | bsz 468.7 | num_updates 20 | lr 0.0004 | gnorm 3.029 | clip 0 | train_wall 1 | gb_free 18.2 | wall 5 (progress_bar.py:267, print())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:10]    INFO >> epoch 002 | valid on 'valid' subset | loss 6.08 | wps 0 | wpb 607 | bsz 607 | num_updates 20 | best_loss 6.08 (progress_bar.py:267, print())\u001b[0m\n",
      "\u001b[32m[2022-10-17 15:35:11]    INFO >> saved checkpoint /mnt/gold/bizq/ncc_data/.ncc/stack_overflow/summarization/csharp/data-mmap/seq2seq/checkpoints/checkpoint_best.pt (epoch 2 @ 20 updates, score 6.08) (writing took 0.239104 seconds) (checkpoint_utils.py:78, save_checkpoint())\u001b[0m\n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"naturalcc/run/type_prediction/typilus/train.py\", line 332, in <module>\n",
      "    cli_main()\n",
      "  File \"naturalcc/run/type_prediction/typilus/train.py\", line 327, in cli_main\n",
      "    single_main(args)\n",
      "  File \"naturalcc/run/type_prediction/typilus/train.py\", line 246, in single_main\n",
      "    train(args, trainer, task, epoch_itr)\n",
      "  File \"/home/dell/anaconda3/envs/gnn/lib/python3.8/contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"naturalcc/run/type_prediction/typilus/train.py\", line 55, in train\n",
      "    log_output = trainer.train_step(samples)\n",
      "  File \"/home/dell/anaconda3/envs/gnn/lib/python3.8/contextlib.py\", line 75, in inner\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/dell/Code/jupyter/naturalcc/ncc/trainers/ncc_trainers.py\", line 467, in train_step\n",
      "    self.optimizer.step()\n",
      "  File \"/home/dell/Code/jupyter/naturalcc/ncc/optimizers/bmuf.py\", line 157, in step\n",
      "    self._optimizer.step(closure)\n",
      "  File \"/home/dell/Code/jupyter/naturalcc/ncc/optimizers/torch_optimizers/adam.py\", line 25, in step\n",
      "    self._optimizer.step()\n",
      "  File \"/home/dell/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/optim/optimizer.py\", line 88, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dell/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/autograd/grad_mode.py\", line 28, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/dell/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/optim/adam.py\", line 133, in step\n",
      "    F.adam(params_with_grad,\n",
      "  File \"/home/dell/anaconda3/envs/gnn/lib/python3.8/site-packages/torch/optim/_functional.py\", line 94, in adam\n",
      "    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python naturalcc/run/type_prediction/typilus/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "90f4c02e-a0d1-4e28-ac1a-2e55380d25a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[37mdell-gpu           \u001b[m  Sun Oct 16 14:47:50 2022  \u001b[1m\u001b[30m460.56\u001b[m\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 34'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m24268\u001b[m MB |\n",
      "\u001b[36m[1]\u001b[m \u001b[34mGeForce RTX 3090\u001b[m |\u001b[31m 39'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m    0\u001b[m / \u001b[33m24268\u001b[m MB |\n"
     ]
    }
   ],
   "source": [
    "!gpustat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8edde-dd77-4bad-be0d-de04088e881c",
   "metadata": {},
   "source": [
    "# 模型评价"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eddf0e3-58d2-4477-9f28-d9691b493b29",
   "metadata": {},
   "source": [
    "**挑战1**. 我们在训练代码中插入了模型的评价代码，试着用它们评价模型的准确率！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c664d7-2062-4b63-aa14-b1e1574d3eeb",
   "metadata": {},
   "source": [
    "# 拓展研究"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f89e6-2871-4de4-b8cd-d30780247980",
   "metadata": {},
   "source": [
    "**挑战2**. 调整Typilus模型的超参数（在`config/typilus.yml`中），试着提高模型的训练准确率。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "530e8702-5341-4262-b058-8c9f20490a93",
   "metadata": {},
   "source": [
    "**挑战3**. 利用`naturalcc`中的其他代码，比较在同样的数据集上，`lstm`,`transformer`,`typilus` 的模型预测能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd819420-4642-43bf-a79d-6541b3b5900f",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**挑战4**. 修改naturalcc的代码，支持[LAMBDANET](https://arxiv.org/pdf/2005.02161.pdf), [Type4Py](https://arxiv.org/pdf/2101.04470.pdf), [Plato](https://arxiv.org/pdf/2107.00157.pdf) 等模型。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('typilus')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0052dc2d9a001ea098bce353c541346da5473321a5f058a114f7fbe16460a9dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
